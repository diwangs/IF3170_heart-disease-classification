{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize path constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "RAW_DATA_PATH = '{}/raw'.format(DATA_PATH)\n",
    "PROCESSED_DATA_PATH = '{}/processed'.format(DATA_PATH)\n",
    "\n",
    "MODEL_PATH = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read processed data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('{}/processed_data.csv'.format(PROCESSED_DATA_PATH))\n",
    "X = data.drop(['heart_disease_diagnosis'], axis=1).values\n",
    "y = data['heart_disease_diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold():\n",
    "    return KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "def print_cv_result(model, X, y):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    kfold = get_kfold()\n",
    "    \n",
    "    for train_idx, validation_idx in kfold.split(X, y):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_validation = X[validation_idx]\n",
    "        y_validation = y[validation_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        prediction = model.predict(X_validation)\n",
    "\n",
    "        accuracy = accuracy_score(y_validation, prediction)\n",
    "        precision = precision_score(y_validation, prediction, average='macro')\n",
    "        recall = recall_score(y_validation, prediction, average='macro')\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    print('--- Validation Metrics ---')\n",
    "    print('Accuracy  = {:.3f}'.format(np.mean(accuracy_scores)))\n",
    "    print('Precision = {:.3f}'.format(np.mean(precision_scores)))\n",
    "    print('Recall    = {:.3f}'.format(np.mean(recall_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.531\n",
      "Precision = 0.348\n",
      "Recall    = 0.343\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Naive Bayes'\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(nb_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In K-Nearest Neighbors algorithm, it's really important to scale the features first (feature scaling).\n",
    "Since the range of values of raw data varies widely, in K-Nearest Neighbors algoritm, objective functions will not work properly without normalization. For example, the majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-Nearest Neighbor ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.546\n",
      "Precision = 0.350\n",
      "Recall    = 0.331\n"
     ]
    }
   ],
   "source": [
    "model_name = 'K-Nearest Neighbor'\n",
    "knn_model = KNeighborsClassifier()\n",
    "X_Scaled = preprocessing.scale(X)\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(knn_model, X_Scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.451\n",
      "Precision = 0.320\n",
      "Recall    = 0.299\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Decision Tree'\n",
    "dtc_model = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(dtc_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANN ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.570\n",
      "Precision = 0.367\n",
      "Recall    = 0.349\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ANN'\n",
    "ann_model = MLPClassifier(random_state=1, activation='logistic')\n",
    "X_Scaled = preprocessing.scale(X)\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(ann_model, X_Scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Best Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)]\n",
    "}\n",
    "\n",
    "best_model = GridSearchCV(MLPClassifier(random_state=1, activation='logistic'),\n",
    "                          param_grid,\n",
    "                          cv=get_kfold(),\n",
    "                          scoring='accuracy')\n",
    "\n",
    "best_model.fit(X_Scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.5815147625160462\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy:', best_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open('{}/best_model.pkl'.format(MODEL_PATH), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
