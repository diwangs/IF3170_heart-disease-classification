{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize path constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "RAW_DATA_PATH = '{}/raw'.format(DATA_PATH)\n",
    "PROCESSED_DATA_PATH = '{}/processed'.format(DATA_PATH)\n",
    "\n",
    "MODEL_PATH = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read processed data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('{}/processed_data.csv'.format(PROCESSED_DATA_PATH))\n",
    "X = data.drop(['heart_disease_diagnosis','sex','num_of_major_vessels'], axis=1)\n",
    "y = data['heart_disease_diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_data_partition(X, y):\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_true)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_true, average='macro')\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_true, average='macro')\n",
    "    \n",
    "    print('--- Validation Metrics ---')\n",
    "    print('Accuracy  = {:.3f}'.format(accuracy))\n",
    "    print('Precision = {:.3f}'.format(precision))\n",
    "    print('Recall    = {:.3f}'.format(recall))\n",
    "\n",
    "def print_cv_result(model, X, y):\n",
    "    # Partition data\n",
    "    X_train, X_validation, y_train, y_validation = get_cv_data_partition(X, y)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict validation\n",
    "    prediction = model.predict(X_validation)\n",
    "    \n",
    "    # Print validation metrics\n",
    "    print_metrics(y_validation, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'print_cv_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3c300f9d834a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=== {} ===\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_cv_result' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'Naive Bayes'\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(nb_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-Nearest Neighbor ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.429\n",
      "Precision = 0.184\n",
      "Recall    = 0.218\n"
     ]
    }
   ],
   "source": [
    "model_name = 'K-Nearest Neighbor'\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(knn_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.455\n",
      "Precision = 0.335\n",
      "Recall    = 0.321\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Decision Tree'\n",
    "dtc_model = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(dtc_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANN ===\n",
      "\n",
      "Iteration 1, loss = 1.44603137\n",
      "Iteration 2, loss = 1.36179690\n",
      "Iteration 3, loss = 1.31641627\n",
      "Iteration 4, loss = 1.28611168\n",
      "Iteration 5, loss = 1.26701383\n",
      "Iteration 6, loss = 1.25047268\n",
      "Iteration 7, loss = 1.23935273\n",
      "Iteration 8, loss = 1.23155788\n",
      "Iteration 9, loss = 1.22591125\n",
      "Iteration 10, loss = 1.22150550\n",
      "Iteration 11, loss = 1.21664599\n",
      "Iteration 12, loss = 1.21147469\n",
      "Iteration 13, loss = 1.20848573\n",
      "Iteration 14, loss = 1.20550590\n",
      "Iteration 15, loss = 1.20034981\n",
      "Iteration 16, loss = 1.19591337\n",
      "Iteration 17, loss = 1.19271237\n",
      "Iteration 18, loss = 1.18916824\n",
      "Iteration 19, loss = 1.18239896\n",
      "Iteration 20, loss = 1.17976465\n",
      "Iteration 21, loss = 1.18163414\n",
      "Iteration 22, loss = 1.17997689\n",
      "Iteration 23, loss = 1.17493432\n",
      "Iteration 24, loss = 1.17041438\n",
      "Iteration 25, loss = 1.16788758\n",
      "Iteration 26, loss = 1.16317273\n",
      "Iteration 27, loss = 1.16441787\n",
      "Iteration 28, loss = 1.16055251\n",
      "Iteration 29, loss = 1.15655046\n",
      "Iteration 30, loss = 1.15507686\n",
      "Iteration 31, loss = 1.15293015\n",
      "Iteration 32, loss = 1.15054848\n",
      "Iteration 33, loss = 1.15120104\n",
      "Iteration 34, loss = 1.15435569\n",
      "Iteration 35, loss = 1.14746522\n",
      "Iteration 36, loss = 1.14711398\n",
      "Iteration 37, loss = 1.14072380\n",
      "Iteration 38, loss = 1.14748223\n",
      "Iteration 39, loss = 1.14366466\n",
      "Iteration 40, loss = 1.14454815\n",
      "Iteration 41, loss = 1.13847464\n",
      "Iteration 42, loss = 1.13798134\n",
      "Iteration 43, loss = 1.13587170\n",
      "Iteration 44, loss = 1.12872192\n",
      "Iteration 45, loss = 1.13823870\n",
      "Iteration 46, loss = 1.13488004\n",
      "Iteration 47, loss = 1.12674324\n",
      "Iteration 48, loss = 1.12580257\n",
      "Iteration 49, loss = 1.12773599\n",
      "Iteration 50, loss = 1.12261851\n",
      "Iteration 51, loss = 1.12767446\n",
      "Iteration 52, loss = 1.12014352\n",
      "Iteration 53, loss = 1.13229863\n",
      "Iteration 54, loss = 1.12362371\n",
      "Iteration 55, loss = 1.12014346\n",
      "Iteration 56, loss = 1.11701453\n",
      "Iteration 57, loss = 1.11557221\n",
      "Iteration 58, loss = 1.12856710\n",
      "Iteration 59, loss = 1.11760312\n",
      "Iteration 60, loss = 1.11675657\n",
      "Iteration 61, loss = 1.10924281\n",
      "Iteration 62, loss = 1.10644129\n",
      "Iteration 63, loss = 1.10579065\n",
      "Iteration 64, loss = 1.10350457\n",
      "Iteration 65, loss = 1.10348172\n",
      "Iteration 66, loss = 1.10420034\n",
      "Iteration 67, loss = 1.10359926\n",
      "Iteration 68, loss = 1.10205677\n",
      "Iteration 69, loss = 1.09918260\n",
      "Iteration 70, loss = 1.10143849\n",
      "Iteration 71, loss = 1.10269916\n",
      "Iteration 72, loss = 1.10475080\n",
      "Iteration 73, loss = 1.09617260\n",
      "Iteration 74, loss = 1.09980613\n",
      "Iteration 75, loss = 1.09776794\n",
      "Iteration 76, loss = 1.10123612\n",
      "Iteration 77, loss = 1.09569683\n",
      "Iteration 78, loss = 1.09812499\n",
      "Iteration 79, loss = 1.09581324\n",
      "Iteration 80, loss = 1.09669969\n",
      "Iteration 81, loss = 1.09305931\n",
      "Iteration 82, loss = 1.09027165\n",
      "Iteration 83, loss = 1.09360473\n",
      "Iteration 84, loss = 1.09557567\n",
      "Iteration 85, loss = 1.09166221\n",
      "Iteration 86, loss = 1.09181905\n",
      "Iteration 87, loss = 1.08605934\n",
      "Iteration 88, loss = 1.09066047\n",
      "Iteration 89, loss = 1.08836876\n",
      "Iteration 90, loss = 1.09342393\n",
      "Iteration 91, loss = 1.08307469\n",
      "Iteration 92, loss = 1.09001669\n",
      "Iteration 93, loss = 1.08801523\n",
      "Iteration 94, loss = 1.08468858\n",
      "Iteration 95, loss = 1.08228744\n",
      "Iteration 96, loss = 1.07685508\n",
      "Iteration 97, loss = 1.07706582\n",
      "Iteration 98, loss = 1.08721597\n",
      "Iteration 99, loss = 1.07949331\n",
      "Iteration 100, loss = 1.08037967\n",
      "Iteration 101, loss = 1.07577563\n",
      "Iteration 102, loss = 1.07957479\n",
      "Iteration 103, loss = 1.08159791\n",
      "Iteration 104, loss = 1.07167410\n",
      "Iteration 105, loss = 1.07514149\n",
      "Iteration 106, loss = 1.07339905\n",
      "Iteration 107, loss = 1.07625284\n",
      "Iteration 108, loss = 1.07744004\n",
      "Iteration 109, loss = 1.06961822\n",
      "Iteration 110, loss = 1.06850617\n",
      "Iteration 111, loss = 1.06789558\n",
      "Iteration 112, loss = 1.06718535\n",
      "Iteration 113, loss = 1.06616987\n",
      "Iteration 114, loss = 1.06421538\n",
      "Iteration 115, loss = 1.06901154\n",
      "Iteration 116, loss = 1.06152957\n",
      "Iteration 117, loss = 1.06632183\n",
      "Iteration 118, loss = 1.06505853\n",
      "Iteration 119, loss = 1.06217598\n",
      "Iteration 120, loss = 1.06094718\n",
      "Iteration 121, loss = 1.05744546\n",
      "Iteration 122, loss = 1.05756273\n",
      "Iteration 123, loss = 1.05716253\n",
      "Iteration 124, loss = 1.05831280\n",
      "Iteration 125, loss = 1.06196773\n",
      "Iteration 126, loss = 1.05480040\n",
      "Iteration 127, loss = 1.05666328\n",
      "Iteration 128, loss = 1.05760775\n",
      "Iteration 129, loss = 1.06152358\n",
      "Iteration 130, loss = 1.05270212\n",
      "Iteration 131, loss = 1.07024849\n",
      "Iteration 132, loss = 1.05398356\n",
      "Iteration 133, loss = 1.05310827\n",
      "Iteration 134, loss = 1.05242021\n",
      "Iteration 135, loss = 1.04806389\n",
      "Iteration 136, loss = 1.05350000\n",
      "Iteration 137, loss = 1.05165563\n",
      "Iteration 138, loss = 1.04800512\n",
      "Iteration 139, loss = 1.04942426\n",
      "Iteration 140, loss = 1.05407885\n",
      "Iteration 141, loss = 1.04753613\n",
      "Iteration 142, loss = 1.04683021\n",
      "Iteration 143, loss = 1.04729479\n",
      "Iteration 144, loss = 1.04435717\n",
      "Iteration 145, loss = 1.04106873\n",
      "Iteration 146, loss = 1.04000967\n",
      "Iteration 147, loss = 1.04882644\n",
      "Iteration 148, loss = 1.04211987\n",
      "Iteration 149, loss = 1.04232809\n",
      "Iteration 150, loss = 1.04129506\n",
      "Iteration 151, loss = 1.04060435\n",
      "Iteration 152, loss = 1.04032447\n",
      "Iteration 153, loss = 1.04773626\n",
      "Iteration 154, loss = 1.03673445\n",
      "Iteration 155, loss = 1.04756720\n",
      "Iteration 156, loss = 1.03435300\n",
      "Iteration 157, loss = 1.05758776\n",
      "Iteration 158, loss = 1.03733732\n",
      "Iteration 159, loss = 1.04248344\n",
      "Iteration 160, loss = 1.03286506\n",
      "Iteration 161, loss = 1.03720890\n",
      "Iteration 162, loss = 1.03263273\n",
      "Iteration 163, loss = 1.02883280\n",
      "Iteration 164, loss = 1.02740056\n",
      "Iteration 165, loss = 1.02811468\n",
      "Iteration 166, loss = 1.02836951\n",
      "Iteration 167, loss = 1.03255950\n",
      "Iteration 168, loss = 1.02925625\n",
      "Iteration 169, loss = 1.02703203\n",
      "Iteration 170, loss = 1.02488822\n",
      "Iteration 171, loss = 1.02450418\n",
      "Iteration 172, loss = 1.02830801\n",
      "Iteration 173, loss = 1.02440500\n",
      "Iteration 174, loss = 1.02495339\n",
      "Iteration 175, loss = 1.02315844\n",
      "Iteration 176, loss = 1.01974304\n",
      "Iteration 177, loss = 1.01965721\n",
      "Iteration 178, loss = 1.01740577\n",
      "Iteration 179, loss = 1.01684417\n",
      "Iteration 180, loss = 1.01476843\n",
      "Iteration 181, loss = 1.01781675\n",
      "Iteration 182, loss = 1.01538933\n",
      "Iteration 183, loss = 1.02220039\n",
      "Iteration 184, loss = 1.01777695\n",
      "Iteration 185, loss = 1.01557143\n",
      "Iteration 186, loss = 1.01315880\n",
      "Iteration 187, loss = 1.01616746\n",
      "Iteration 188, loss = 1.01618031\n",
      "Iteration 189, loss = 1.01696510\n",
      "Iteration 190, loss = 1.01353298\n",
      "Iteration 191, loss = 1.01306792\n",
      "Iteration 192, loss = 1.00794596\n",
      "Iteration 193, loss = 1.01008631\n",
      "Iteration 194, loss = 1.00704334\n",
      "Iteration 195, loss = 1.01407312\n",
      "Iteration 196, loss = 1.00889158\n",
      "Iteration 197, loss = 1.00920725\n",
      "Iteration 198, loss = 1.00850102\n",
      "Iteration 199, loss = 1.00415499\n",
      "Iteration 200, loss = 1.01275939\n",
      "--- Validation Metrics ---\n",
      "Accuracy  = 0.635\n",
      "Precision = 0.423\n",
      "Recall    = 0.371\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ANN'\n",
    "ann_model = MLPClassifier(random_state=1, alpha=0.00210, epsilon=1e-8, activation='logistic', verbose=True)\n",
    "\n",
    "print('=== {} ===\\n'.format(model_name))\n",
    "print_cv_result(ann_model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ann_model\n",
    "pickle.dump(best_model, open('{}/best_model.pkl'.format(MODEL_PATH), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
